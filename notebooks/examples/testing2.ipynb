{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../modules')\n",
    "import twitter_scrape_profiles as tsp\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "import pandas as pd\n",
    "import twint\n",
    "import nest_asyncio \n",
    "import datetime\n",
    "import os\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_profiles = ['JosephineFock', 'TorstenGejl', 'Kristianthdahl', 'MrMesserschmidt', 'LiseBech', 'SorenPape', \n",
    "                'metteabildgaard', 'orlaosterby', 'PSkipperEL', 'MaiVilladsen', 'pederhvelplund', 'AlexVanopslagh', \n",
    "                'olebirkolesen', 'oestergaard', 'IdaAuken', 'stinuslindgreen', 'PiaOlsen', 'signe_munk', 'JakobEllemann', \n",
    "                'aahlers', 'kimvalentinDK', 'MogensJensenS', 'DanJoergensen', 'Paulin_Anne', 'Rstoklund', \n",
    "                'Isabella Arendt', 'ammitzbollbille']\n",
    "\n",
    "tweet_columns = ['id', 'conversation_id', 'created_at', 'date', 'time', 'timezone', 'user_id', 'username', 'name', \n",
    "                     'place', 'tweet', 'urls', 'replies_count', 'retweets_count', 'likes_count', 'hashtags', 'link', \n",
    "                     'retweet', 'user_rt_id', 'user_rt', 'retweet_id', 'reply_to', 'retweet_date']\n",
    "\n",
    "datadir = \"../data/tweets/\"\n",
    "\n",
    "#end_time = datetime.datetime(2020, 8, 1)\n",
    "\n",
    "#dt_now = datetime.datetime.now()\n",
    "\n",
    "#while dt_now < end_time:\n",
    "#    tsp.update_tweets_data(twitter_profiles, tweet_columns, datadir)\n",
    "#    time_out = 24 * 60 * 60\n",
    "#    time.sleep(time_out)\n",
    "#    dt_now = datetime.datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No existing log for last run time. Using default (2020-01-01 08:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oct 02 2020 11:16: Running scrape for JosephineFock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 1.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 8.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 27.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 64.0 secs\n"
     ]
    }
   ],
   "source": [
    "tsp.update_tweets_data(twitter_profiles, tweet_columns, datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_user(profile, date, datadir, columns):\n",
    "    filename = profile + '.csv'\n",
    "    dt_now = datetime.datetime.now().strftime(\"%b %d %Y %H:%M\")\n",
    "    \n",
    "    c = twint.Config()\n",
    "    c.Username = profile\n",
    "    c.Since = date\n",
    "    c.Store_csv = True\n",
    "    c.Hide_output = True\n",
    "    c.Custom['tweet'] = columns\n",
    "    c.Output = datadir + filename\n",
    "    \n",
    "    print(\"{time}: Running scrape for {user}\".format(time = dt_now, user = profile))\n",
    "    logger.info(\"{time}: Running scrape for {user}\".format(time = dt_now, user = profile))\n",
    "    twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data/testing/tweets/\"\n",
    "filename = \"jos.csv\"\n",
    "profile = 'JosephineFock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = twint.Config()\n",
    "c.Username = profile\n",
    "c.Since = '2020-09-01'\n",
    "c.Store_csv = True\n",
    "c.Hide_output = True\n",
    "c.Custom['tweet'] = tweet_columns\n",
    "c.Output = datadir + filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 1.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 8.0 secs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f28f8e9aab1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtwint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\twint\\lib\\site-packages\\twint\\run.py\u001b[0m in \u001b[0;36mSearch\u001b[1;34m(config, callback)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProfile_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPandas_au\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpanda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_autoget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tweet\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\twint\\lib\\site-packages\\twint\\run.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(config, callback)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m     \u001b[0mget_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTwint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mFavorites\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\twint\\lib\\site-packages\\nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_destroy_pending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stopping\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\twint\\lib\\site-packages\\nest_asyncio.py\u001b[0m in \u001b[0;36m_run_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[1;32melse\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_when\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscheduled\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mevent_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\twint\\lib\\selectors.py\u001b[0m in \u001b[0;36mselect\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\twint\\lib\\selectors.py\u001b[0m in \u001b[0;36m_select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'win32'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 27.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 64.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 125.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 216.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 343.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 512.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 729.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n",
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!"
     ]
    }
   ],
   "source": [
    "twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//nyheder.tv2.dk/politik/2020-10-14-landsformand-gaar-i-rette-med-ida-auken-jeg-kender-ikke-til-det-moede-i-2017 Landsformand går i rette med Ida Auken: - Jeg kender ikke til det møde i 2017\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import scrapy\n",
    "from scrapy import Selector\n",
    "\n",
    "#str(bs(requests.get(\"https://stackoverflow.com/questions/54869374/cant-start-spyder-because-of-pyqt5-qtwebkitwidgets\").content))\n",
    "\n",
    "html = requests.get(\"https://nyheder.tv2.dk/politik/\").content\n",
    "soup = bs(html, \"html.parser\")\n",
    "\n",
    "headline = soup.find(\"a\", class_=\"o-teaser_link\")\n",
    "print(headline['href'],\n",
    "      headline['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPolitik \\n                        Landsformand går i rette med Ida Auken: - Jeg kender ikke til det møde i 2017        \\n\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_check(keywords, headline):\n",
    "    '''\n",
    "    Checks whether headline contains keywords.\n",
    "    '''\n",
    "    text = headline['title']\n",
    "    if any(re.match(word, text) for word in keywords):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "keywords = [r'.*']\n",
    "\n",
    "headlines = soup.find_all(\"a\", class_=\"o-teaser_link\")\n",
    "    \n",
    "#extract headlines based on keyword\n",
    "headlines_ext = list()\n",
    "\n",
    "for headline in headlines:\n",
    "    if keyword_check(keywords, headline) == True:\n",
    "        headlines_ext.append(headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_ext = list()\n",
    "for headline in headlines_ext:\n",
    "    if \"https:\" not in headline['href']:\n",
    "        link = \"https:\" + headline['href']\n",
    "    else:\n",
    "        link = headline['href']\n",
    "    links_ext.append(link)\n",
    "links_ext = list(filter(None, links_ext))\n",
    "links_ext = list(set(links_ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://underholdning.tv2.dk/2020-09-04-sangerinden-lever-for-champagne-momenterne-men-hun-har-laert-at-intet-er-gratis',\n",
       " 'https://nyheder.tv2.dk/krimi/2020-10-11-danmark-risikerer-advokatregning-paa-over-10-milliarder-i-udbyttesagen-siger',\n",
       " 'https://nyheder.tv2.dk/samfund/2020-10-12-kommentator-et-enormt-traume-for-radikale-venstre',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-12-morten-oestergaard-sygemelder-sig-chef-faar-en-advarsel',\n",
       " 'https://nyheder.tv2.dk/lokalt/2020-10-14-borgmester-faar-kritik-facebook-opslag-til-dem-jeg-har-klappet-i-roeven-undskyld',\n",
       " 'https://nyheder.tv2.dk/samfund/2020-09-24-19-aarige-amalie-kom-paa-hospice-jeg-graed-som-jeg-aldrig-har-graedt-foer',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-13-erhvervsstyrelsen-gar-ind-i-sag-om-borgmesters-bolighandel',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-11-klimakritik-regeringen-foelger-ikke-anbefalinger-fra-sin-vigtigste-klimaraadgiver',\n",
       " 'https://nyheder.tv2.dk/2020-10-09-foelg-forhandlingerne-om-arne-pensionen-her',\n",
       " 'https://nyheder.tv2.dk/samfund/2020-10-14-politiet-laegger-sig-fladt-ned-og-undskylder-efter-at-have-lukket-koncert-paa',\n",
       " 'https://nyheder.tv2.dk/samfund/2020-10-14-36-haandvaerkere-smittet-med-coronavirus-i-faxe',\n",
       " 'https://nyheder.tv2.dk/2020-10-14-seneste-nyt-om-uro-i-radikale-venstre',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-14-ida-auken-jeg-bad-sofie-carsten-nielsen-om-at-gribe-ind-hun-daekkede-over-ham',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-10-fra-benaegtelse-til-indroemmelse-af-flere-kraenkelsessager-her-er-forloebet',\n",
       " 'https://nyheder.tv2.dk/udland/2020-10-05-tusindvis-af-bevaebnede-amerikanere-goer-sig-klar-der-kommer-en-krig-til-november',\n",
       " 'https://sport.tv2.dk/cykling/2020-10-14-danske-topryttere-udgaar-af-klassiker',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-11-opgoer-i-kristendemokraterne-vil-vaelte-vikaren-fra-himlen',\n",
       " 'https://nyheder.tv2.dk/samfund/2020-10-14-492-nye-smittetilfaelde-med-coronavirus',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-13-sofie-carsten-nielsen-faar-opbakning-fra-hovedbestyrelse',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-09-df-udeblev-fra-arne-forhandlinger-disse-to-ting-er-de-uenige-om',\n",
       " 'https://nyheder.tv2.dk/samfund/2020-10-11-nyeste-coronatal-fra-danmark-og-verden-saa-mange-er-smittede-doede-og-indlagte',\n",
       " 'https://sport.tv2.dk/haandbold/2020-10-14-topklub-er-taet-paa-dansk-landsholdsbobler',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-11-de-radikale-vil-lave-undersoegelse-af-sexchikane-i-partiet',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-13-folketingsmedlem-foelte-sig-presset-til-at-fortaelle-om-oestergaards-kraenkelser',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-14-landsformand-gaar-i-rette-med-ida-auken-jeg-kender-ikke-til-det-moede-i-2017',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-09-sofie-carsten-nielsen-oestergaard-var-ikke-aerlig-om-andre-kraenkelser',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-09-oestergaards-fremtid-i-dansk-politik-er-usikker-siger-eksperter',\n",
       " 'https://nyheder.tv2.dk/2020-10-14-seneste-nyt-om-coronavirus',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-13-sofie-carsten-nielsen-afviste-at-kende-til-flere-sager-om-morten-oestergaard-men',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-13-her-er-de-tre-klagesager-mod-oestergaard',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-11-efter-ny-debat-om-jeppe-kofods-sexsag-stor-stoette-fra-socialdemokratiets-bagland',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-09-de-har-fuppet-macron-prins-harry-og-elton-john-nu-siger-russisk-satireduo-at-de',\n",
       " 'https://nyheder.tv2.dk/udland/2020-10-14-54-ton-stor-bombe-eksploderede-under-desarmering-i-polen',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-12-se-videoen-danske-politikere-snydt-af-russisk-satireduo',\n",
       " 'https://nyheder.tv2.dk/2020-10-08-hun-raabte-om-hjaelp-til-at-flygte-fra-vold-og-mishandling-men-kommunen-overhoerte-hende',\n",
       " 'https://nyheder.tv2.dk/politik/2020-10-10-flertal-enige-om-ny-ret-til-tidlig-pension-til-baade-arne-og-konen']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_info(link, keywords, source_url = \"https://nyheder.tv2.dk/politik/\"):\n",
    "    '''\n",
    "    Creates a dictionary of information from a headline.\n",
    "    '''\n",
    "    i = 3\n",
    "    \n",
    "    art_uuid = str(uuid.uuid4())\n",
    "    encounter_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "    \n",
    "    while i > 0:\n",
    "        time_out = randint(2, 5)\n",
    "        time.sleep(time_out)\n",
    "        req = requests.get(link, timeout = 5.0)\n",
    "        response_code = req.status_code\n",
    "\n",
    "        if response_code == 200:     \n",
    "\n",
    "            info = dict()\n",
    "\n",
    "            html = requests.get(link, timeout = 5.0).content\n",
    "            soup = bs(html, \"html.parser\")\n",
    "\n",
    "            article_title = soup.title.get_text()\n",
    "            try:\n",
    "                article_datetime = soup.find(\"meta\", attrs={\"name\": \"article:published_time\"})['content']\n",
    "            except TypeError:\n",
    "                article_datetime = ''\n",
    "\n",
    "            matches = list(compress(keywords, [keyword in article_title.lower() for keyword in keywords]))\n",
    "\n",
    "            info['uuid'] = art_uuid\n",
    "            info['article_accessed'] = 1\n",
    "            info['newspaper_name'] = 'TV2 Nyheder'\n",
    "            info['newspaper_frontpage_url'] = source_url\n",
    "            info['keywords_search'] = keywords\n",
    "            info['keywords_match'] = matches\n",
    "            info['article_title'] = article_title\n",
    "            info['article_link'] = link\n",
    "            info['article_datetime'] = article_datetime\n",
    "            info['encounter_datetime'] = encounter_time\n",
    "            info['article_source'] = str(bs(req.content, \"html.parser\"))\n",
    "            \n",
    "            return(info)\n",
    "        else:\n",
    "            i = i -1\n",
    "        \n",
    "        if i == 0:\n",
    "            \n",
    "            info = dict()\n",
    "            \n",
    "            info['uuid'] = art_uuid\n",
    "            info['article_accessed'] = 0\n",
    "            info['newspaper_name'] = 'TV2 Nyheder'\n",
    "            info['newspaper_frontpage_url'] = source_url\n",
    "            info['keywords_search'] = keywords\n",
    "            info['keywords_match'] = ''\n",
    "            info['article_title'] = ''\n",
    "            info['article_link'] = link\n",
    "            info['article_datetime'] = ''\n",
    "            info['encounter_datetime'] = encounter_time\n",
    "            info['article_source'] = ''\n",
    "            \n",
    "            return(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import requests\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import re\n",
    "import time\n",
    "import uuid\n",
    "import random\n",
    "from random import randint\n",
    "from itertools import compress\n",
    "import json\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def keyword_check(keywords, headline):\n",
    "    '''\n",
    "    Checks whether headline contains keywords.\n",
    "    '''\n",
    "    text = headline['title']\n",
    "    if any(word in text for word in keywords):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_article_info(link, keywords, source_url = \"https://nyheder.tv2.dk/politik/\"):\n",
    "    '''\n",
    "    Creates a dictionary of information from a headline.\n",
    "    '''\n",
    "    i = 3\n",
    "    \n",
    "    art_uuid = str(uuid.uuid4())\n",
    "    encounter_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "    \n",
    "    while i > 0:\n",
    "        time_out = randint(2, 5)\n",
    "        time.sleep(time_out)\n",
    "        req = requests.get(link, timeout = 5.0)\n",
    "        response_code = req.status_code\n",
    "\n",
    "        if response_code == 200:     \n",
    "\n",
    "            info = dict()\n",
    "\n",
    "            html = requests.get(link, timeout = 5.0).content\n",
    "            soup = bs(html, \"html.parser\")\n",
    "\n",
    "            article_title = soup.title.get_text()\n",
    "            try:\n",
    "                article_datetime = soup.find(\"meta\", attrs={\"name\": \"article:published_time\"})['content']\n",
    "            except TypeError:\n",
    "                article_datetime = ''\n",
    "\n",
    "            matches = list(compress(keywords, [keyword in article_title.lower() for keyword in keywords]))\n",
    "\n",
    "            info['uuid'] = art_uuid\n",
    "            info['article_accessed'] = 1\n",
    "            info['newspaper_name'] = 'TV2 Nyheder'\n",
    "            info['newspaper_frontpage_url'] = source_url\n",
    "            info['keywords_search'] = keywords\n",
    "            info['keywords_match'] = matches\n",
    "            info['article_title'] = article_title\n",
    "            info['article_link'] = link\n",
    "            info['article_datetime'] = article_datetime\n",
    "            info['encounter_datetime'] = encounter_time\n",
    "            info['article_source'] = str(bs(req.content, \"html.parser\"))\n",
    "            \n",
    "            return(info)\n",
    "        else:\n",
    "            i = i -1\n",
    "        \n",
    "        if i == 0:\n",
    "            \n",
    "            info = dict()\n",
    "            \n",
    "            info['uuid'] = art_uuid\n",
    "            info['article_accessed'] = 0\n",
    "            info['newspaper_name'] = 'TV2 Nyheder'\n",
    "            info['newspaper_frontpage_url'] = source_url\n",
    "            info['keywords_search'] = keywords\n",
    "            info['keywords_match'] = ''\n",
    "            info['article_title'] = ''\n",
    "            info['article_link'] = link\n",
    "            info['article_datetime'] = ''\n",
    "            info['encounter_datetime'] = encounter_time\n",
    "            info['article_source'] = ''\n",
    "            \n",
    "            return(info)\n",
    "\n",
    "def front_page_check(url, keywords, url_list):\n",
    "    '''\n",
    "    Creates dictionary of headlines with various information.\n",
    "    '''    \n",
    "    #selector of main page\n",
    "    url = url\n",
    "    html = requests.get(url, timeout = 5.0).content\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    #get headline soups\n",
    "    headlines = soup.find_all(\"a\", class_=\"o-teaser_link\")\n",
    "\n",
    "    #extract headlines based on keyword\n",
    "    headlines_ext = list()\n",
    "\n",
    "    for headline in headlines:\n",
    "        if keyword_check(keywords, headline) == True:\n",
    "            headlines_ext.append(headline)\n",
    "\n",
    "    #get links from extracted headlines\n",
    "    links_ext = list()\n",
    "    for headline in headlines_ext:\n",
    "        if \"https:\" not in headline['href']:\n",
    "            link = \"https:\" + headline['href']\n",
    "        else:\n",
    "            link = headline['href']\n",
    "        links_ext.append(link)\n",
    "    links_ext = list(filter(None, links_ext))\n",
    "    links_ext = list(set(links_ext))\n",
    "\n",
    "    #get article info\n",
    "    articles = []\n",
    "\n",
    "    for link in links_ext:\n",
    "        if not link in url_list:\n",
    "            art_info = get_article_info(link = link, keywords = keywords)\n",
    "            articles.append(art_info)\n",
    "            url_list.append(link)\n",
    "            time_out = random.uniform(0.5, 2.0)\n",
    "            time.sleep(time_out)\n",
    "            \n",
    "    return(articles)\n",
    "\n",
    "def headline_watch(keywords, datadir, source_url = \"https://nyheder.tv2.dk/politik/\"):\n",
    "    '''\n",
    "    Checks the frontpage and stores info about headlines matching keywords.\n",
    "    '''\n",
    "    keywords = keywords\n",
    "\n",
    "    urldir = datadir + \"urls/\"\n",
    "\n",
    "    urllist_filename = \"tv2_article_urls.txt\"\n",
    "\n",
    "    data_filename = \"tv2_articles.json\"\n",
    "\n",
    "    url_list = []\n",
    "\n",
    "    try:\n",
    "        with open(urldir + urllist_filename, 'r') as f:\n",
    "            for line in f:\n",
    "                url_list.append(line.strip())\n",
    "            f.close()\n",
    "    except IOError:\n",
    "        print(\"No existing url list. Creating new file {}\".format(urllist_filename))\n",
    "        logger.info(\"No existing url list. Creating new file {}\".format(urllist_filename))\n",
    "        if not os.path.isdir(urldir):\n",
    "            os.mkdir(urldir)\n",
    "\n",
    "    try:\n",
    "        with open(datadir + data_filename, 'r') as f:\n",
    "            f.close()\n",
    "    except IOError:\n",
    "        print(\"No existing data file. Creating new file {}\".format(data_filename))\n",
    "        logger.info(\"No existing data file. Creating new file {}\".format(data_filename))\n",
    "        with open(datadir + data_filename, 'w') as f:\n",
    "            json.dump([], f)\n",
    "\n",
    "    i = 3\n",
    "\n",
    "    while i > 0:\n",
    "        try:\n",
    "            response = requests.get(source_url, timeout = 5.0)\n",
    "            break\n",
    "        except:\n",
    "            i = i - 1\n",
    "            time_int = random.uniform(0.1, 0.2) \n",
    "            time.sleep(time_int)\n",
    "            continue\n",
    "\n",
    "    if i > 0: \n",
    "        if response.status_code == 200:\n",
    "            articles = front_page_check(url = source_url, keywords = keywords, url_list = url_list)\n",
    "\n",
    "            if len(articles) != 0:\n",
    "                with open(datadir + data_filename, 'r') as f:\n",
    "                    heads = json.load(f)\n",
    "                    heads = heads + articles\n",
    "                    f.close()\n",
    "                with open(datadir + data_filename, 'w') as file:\n",
    "                    json.dump(heads, file)\n",
    "                file.close()\n",
    "\n",
    "            for article in articles:\n",
    "                url_list.append(article['article_link'])\n",
    "\n",
    "            url_list = list(set(url_list))\n",
    "\n",
    "            with open(urldir + urllist_filename, 'w') as f:\n",
    "                for url in url_list:\n",
    "                    f.write(url + \"\\n\")\n",
    "                f.close()\n",
    "\n",
    "            print(\"TV2 front page checked on {time}. {n} new articles found.\".format(time = datetime.datetime.now(), n = len(articles)))\n",
    "            logger.info(\"TV2 front page checked on {time}. {n} new articles found.\".format(time = datetime.datetime.now(), n = len(articles)))\n",
    "            return\n",
    "    else:\n",
    "        print(\"Error retrieving TV2 front page on {time}. Skipping...\".format(time = datetime.datetime.now()))\n",
    "        logger.warning(\"Error retrieving TV2 front page on {time}. Skipping...\".format(time = datetime.datetime.now()))      \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "parentdir = os.path.dirname(os.path.dirname(os.path.realpath(__name__)))\n",
    "modulesdir = os.path.join(parentdir, \"modules\")\n",
    "import time\n",
    "import datetime\n",
    "from random import randint\n",
    "sys.path.append(modulesdir)\n",
    "import berlingske_fp_watcher as berwatch\n",
    "import politiken_fp_watcher as polwatch\n",
    "import dr_fp_watcher as drwatch\n",
    "import tv2_fp_watcher as tv2watch\n",
    "import logging\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "keywords = [r\".*\"]\n",
    "\n",
    "datadir = \"../data/testing/\"\n",
    "\n",
    "url_list = []\n",
    "url = \"https://nyheder.tv2.dk/politik/\"\n",
    "\n",
    "front_page_check(url = url, keywords = keywords, url_list = url_list)\n",
    "#tv2watch.headline_watch(keywords = keywords, datadir = datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://politiken.dk/indland/politik/art7961058/%C2%BBJeg-ved-ikke-hvad-Ida-Auken-t%C3%A6nker-om-sin-fremtid%C2%AB\n",
      "https://politiken.dk/indland/politik/art7960842/Rasende-Sofie-Carsten-Nielsen-Ida-Auken-kommer-med-falske-anklager\n",
      "https://politiken.dk/indland/politik/art7960667/Jeg-fortalte-hende-hvordan-%C3%98stergaard-befamlede-en-ung-kvinde-og-hun-d%C3%A6kkede-over-ham\n",
      "https://politiken.dk/indland/politik/art7960200/Radikale-byr%C3%B8dder-frygter-for-n%C3%A6ste-%C3%A5rs-valgresultat\n",
      "https://politiken.dk/indland/politik/art7960619/Borgmester-forlader-Venstre-og-stifter-nyt-parti\n",
      "https://politiken.dk/indland/politik/art7960335/De-radikale-vil-oprette-uafh%C3%A6ngig-instans-for-at-d%C3%A6mme-op-for-kr%C3%A6nkelser\n",
      "https://politiken.dk/indland/politik/art7960286/Sofie-Carsten-Nielsen-afviser-at-have-d%C3%A6kket-over-sager\n",
      "https://politiken.dk/indland/politik/art7959470/Radikale-Venstre-er-kollapset-efter-et-kollektivt-granatchok\n",
      "https://politiken.dk/indland/politik/art7959286/Sofie-Carsten-Nielsen-har-kendt-til-endnu-en-intern-kr%C3%A6nkelsessag\n",
      "https://politiken.dk/indland/politik/art7959262/Morten-%C3%98stergaard-sygemelder-sig-efter-kr%C3%A6nkelsessager\n",
      "https://politiken.dk/indland/politik/art7959258/Endnu-et-folketingsmedlem-st%C3%A5r-frem-som-kr%C3%A6nket-af-%C3%98stergaard\n",
      "https://politiken.dk/indland/politik/art7959252/Morten-%C3%98stergaard-kunne-kun-f%C3%A5-p%C3%A5tale-for-kr%C3%A6nkelser.-Nu-f%C3%A5r-sekretariatschef-en-advarsel\n",
      "https://politiken.dk/indland/politik/art7958182/De-radikale-s%C3%A6tter-%C3%98stergaard-unders%C3%B8gelse-i-gang\n",
      "https://politiken.dk/indland/art7957894/Hummelgaard-ryger-helt-op-i-hierarkiet-nu\n",
      "https://politiken.dk/indland/politik/art7957845/Her-er-aftalen-om-ret-til-tidlig-pension\n",
      "https://politiken.dk/indland/politik/art7956339/Fra-kritiseret-%C2%BBfatamorgana%C2%AB-til-en-aftale-om-tidlig-pension\n",
      "https://politiken.dk/indland/politik/art7957842/DF-afviser-skuffelse-over-manglende-udl%C3%A6ndingetiltag\n",
      "https://politiken.dk/indland/politik/art7957836/DI-er-loren-ved-at-sende-tusinder-af-raske-p%C3%A5-tidlig-pension\n",
      "https://politiken.dk/indland/politik/art7957829/SF-og-Enhedslisten-er-glade-for-at-have-Arnes-kone-med-i-aftale\n",
      "https://politiken.dk/indland/politik/art7957823/DF-sikrer-regeringen-flertal-for-ret-til-tidlig-pension\n",
      "https://politiken.dk/indland/politik/art7953388/Familierne-har-k%C3%B8leskabe-men-m%C3%A5-ikke-lave-mad\n",
      "https://politiken.dk/indland/politik/art7957779/DF-Gebyr-p%C3%A5-sprogskoler-skal-skaffe-penge-til-tidlig-pension\n",
      "https://politiken.dk/indland/politik/art7953386/Trods-klar-aftale-kan-asylfamilier-fortsat-ikke-lave-deres-egen-mad\n",
      "https://politiken.dk/indland/politik/art7957367/Der-er-en-personalesag-p%C3%A5-Morten-%C3%98stergaard\n",
      "https://politiken.dk/indland/politik/art7957371/Sofie-Carsten-Nielsen-Jeg-kendte-ikke-til-sagerne\n",
      "https://politiken.dk/indland/politik/art7957250/DF-udebliver-fra-forhandlinger-om-tidlig-pension\n",
      "https://politiken.dk/indland/politik/art7957248/Morten-%C3%98stergaard-erkender-Flere-kvinder-har-oplevet-u%C3%B8nsket-seksuel-opm%C3%A6rksomhed-fra-mig\n",
      "https://politiken.dk/indland/politik/art7956899/%C3%98stergaard-m%C3%A5tte-gerne-informere-gruppen\n",
      "https://politiken.dk/indland/politik/art7955206/Giftpilene-flyver-p%C3%A5-kryds-og-tv%C3%A6rs-hos-de-radikale-efter-%C3%98stergaards-exit\n",
      "https://politiken.dk/indland/politik/art7955778/Morten-%C3%98stergaard-talte-direkte-usandt\n",
      "https://politiken.dk/indland/politik/art7955697/Margrethe-Vestager-kalder-Sofie-Carsten-dedikeret-og-god\n",
      "https://politiken.dk/indland/politik/art7955138/Lige-nu-har-de-fleste-i-den-radikale-gruppe-granatchok\n",
      "https://politiken.dk/indland/politik/art7955012/Lotte-Rod-stemte-ikke-p%C3%A5-Sofie-Carsten-Nielsen-som-ny-leder\n",
      "https://politiken.dk/indland/politik/art7954843/Sp%C3%B8rg-Kristian-Madsen-om-kaosset-hos-de-radikale\n",
      "https://politiken.dk/indland/politik/art7954758/Jeg-fors%C3%B8gte-ikke-at-kv%C3%A6le-sexchikane-sag\n",
      "https://politiken.dk/indland/politik/art7954736/Simon-Emil-Ammitzb%C3%B8ll-Bille-skrotter-sit-parti\n",
      "https://politiken.dk/indland/politik/art7954661/%C2%BBDet-kommer-til-at-kr%C3%A6ve-dialog%C2%AB\n",
      "\n",
      "                Oplev verdens bedste pressefotografierproblem\n",
      "https://politiken.dk/indland/politik/art7954354/Det-er-helt-uforudsigeligt-hvad-der-nu-sker\n",
      "https://politiken.dk/indland/politik/art7954276/%C3%98stergaard-risikerer-at-blive-husket-for-et-megafon-lederskab-der-adskilte-sig-fra-forg%C3%A6ngernes\n",
      "https://politiken.dk/indland/politik/art7954428/Loyal-radikals-fort%C3%A6lling-f%C3%B8rte-til-%C3%98stergaards-fald\n",
      "https://politiken.dk/indland/politik/art7954284/Jeg-vidste-godt-at-det-var-Morten\n",
      "https://politiken.dk/indland/politik/art7954260/En-politisk-tsunami-har-ramt-dansk-politik\n",
      "https://politiken.dk/indland/politik/art7954353/Her-f%C3%A5r-du-overblikket-Kr%C3%A6nkelsessagerne-bliver-ved-med-at-rulle-i-Radikale-Venstre\n",
      "https://politiken.dk/indland/politik/art7954352/Corona-aflivning-af-mink-kan-begynde\n",
      "https://politiken.dk/indland/politik/art7954335/Efter-sejr-i-kampvalg-Sofie-Carsten-Nielsen-var-klar-over-at-h%C3%A5nden-p%C3%A5-Lotte-Rods-l%C3%A5r-tilh%C3%B8rte-%C3%98stergaard\n",
      "https://politiken.dk/indland/politik/art7954302/Ikke-min-mening-at-%C3%98stergaard-skulle-g%C3%A5\n",
      "https://politiken.dk/indland/politik/art7953830/Morten-%C3%98stergaard-f%C3%A6rdig-som-radikal-leder-efter-sexismesag\n",
      "https://politiken.dk/indland/politik/art7954085/Sofie-Carsten-Nielsen-f%C3%A5r-hurtig-ildd%C3%A5b-i-morgen-med-%C3%A5bningstale\n",
      "https://politiken.dk/indland/politik/art7952129/Regeringen-vil-give-syv-kommuner-en-frihed-de-slet-ikke-er-vant-til-p%C3%A5-velf%C3%A6rd\n",
      "https://politiken.dk/indland/politik/art7951522/R-Gr%C3%B8nne-investeringer-skal-v%C3%A6re-varige\n",
      "https://politiken.dk/indland/politik/art7950371/Partiet-m%C3%A5-finde-den-rette-sanktion\n",
      "https://politiken.dk/indland/politik/art7946493/Lykketoft-har-kaldt-det-en-%C2%BBskandale%C2%AB.-Nu-skal-vism%C3%A6nd-lave-eftersyn-af-udsk%C3%A6ldte-regnemodeller\n",
      "https://politiken.dk/indland/politik/art7949756/Disse-politikere-skal-f%C3%B8re-Enhedslistens-succes-videre-ved-n%C3%A6ste-valg\n"
     ]
    }
   ],
   "source": [
    "for headline in headlines_ext:\n",
    "    try:\n",
    "        print(headline.a['href'])\n",
    "    except:\n",
    "        print(headline.get_text() + \"problem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
