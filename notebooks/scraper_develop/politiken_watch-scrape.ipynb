{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Politiken forside scraper\n",
    "\n",
    "https://askubuntu.com/questions/396654/how-to-run-a-python-program-in-the-background-even-after-closing-the-terminal\n",
    "\n",
    "https://www.programiz.com/python-programming/json\n",
    "\n",
    "**Krav:**\n",
    "- Scanne Politikens forside med jævne mellemrum\n",
    "- Scanne forside-titler for indhold af bestemte nøgleord\n",
    "- Lagre information om artikler, der indeholder disse nøgleord\n",
    "- Tilføje til JSON\n",
    "- Kontrol for artikel allerede er lagret\n",
    "- Skal forvente timeouts\n",
    "- Evt. mailvarsel\n",
    "\n",
    "**Udfordring:**\n",
    "- Varsling hvis script kører død?\n",
    "\n",
    "**JSON-opbygning:**\n",
    "- entry[id]\n",
    "    - newspaper_name: ...\n",
    "    - newspaper_frontpage-url: ...\n",
    "    - frontpage_selector:\n",
    "    - keyword_search:[..., ..., ...]\n",
    "    - keyword_match: [...]\n",
    "    - article_title: ...\n",
    "    - article_link: ...\n",
    "    - article_html: ...\n",
    "    - article_datetime: ...\n",
    "    - encounter_datetime: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scrapy\n",
    "import requests\n",
    "from scrapy import Selector\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import re\n",
    "import time\n",
    "import uuid\n",
    "from random import randint\n",
    "from itertools import compress\n",
    "import json\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions\n",
    "def keyword_check(keywords, headline):\n",
    "    text = headline.css(\" ::text\").getall()\n",
    "    text = ' '.join(text)\n",
    "    text = text.lower()\n",
    "    if any(word in text for word in keywords):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_article_info(link):\n",
    "    \n",
    "    i = 3\n",
    "    \n",
    "    art_uuid = str(uuid.uuid4())\n",
    "    encounter_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "    \n",
    "    while i > 0:\n",
    "        time_out = randint(2, 5)\n",
    "        time.sleep(time_out)\n",
    "        response_code = requests.get(link).status_code\n",
    "\n",
    "        if response_code == 200:     \n",
    "\n",
    "            info = dict()\n",
    "\n",
    "            html = requests.get(link).content\n",
    "            sel = Selector(text = html)\n",
    "\n",
    "            title_sel = \"title ::text\"\n",
    "            datetime_xpath = '//meta[contains(@property,\"article:published_time\")]/@content'\n",
    "\n",
    "            article_title = sel.css(title_sel).get()\n",
    "            article_datetime = sel.xpath(datetime_xpath).get()\n",
    "\n",
    "            matches = list(compress(keywords, [keyword in article_title.lower() for keyword in keywords]))\n",
    "\n",
    "            info['uuid'] = art_uuid\n",
    "            info['article_accessed'] = 1\n",
    "            info['newspaper_name'] = 'Politiken'\n",
    "            info['newspaper_frontpage_url'] = 'https://politiken.dk/'\n",
    "            info['frontpage_selector'] = \"section.frontpage__section\"\n",
    "            info['keywords_search'] = keywords\n",
    "            info['keywords_match'] = matches\n",
    "            info['article_title'] = article_title\n",
    "            info['article_link'] = link\n",
    "            info['article_datetime'] = article_datetime\n",
    "            info['encounter_datetime'] = encounter_time\n",
    "            return(info)\n",
    "        else:\n",
    "            i = i -1\n",
    "        \n",
    "        if i == 0:\n",
    "            \n",
    "            info = dict()\n",
    "            \n",
    "            info['uuid'] = art_uuid\n",
    "            info['article_accessed'] = 0\n",
    "            info['newspaper_name'] = 'Politiken'\n",
    "            info['newspaper_frontpage_url'] = 'https://politiken.dk/'\n",
    "            info['frontpage_selector'] = \"section.frontpage__section\"\n",
    "            info['keywords_search'] = keywords\n",
    "            info['keywords_match'] = ''\n",
    "            info['article_title'] = ''\n",
    "            info['article_link'] = link\n",
    "            info['article_datetime'] = ''\n",
    "            info['encounter_datetime'] = encounter_time\n",
    "            return(info)\n",
    "\n",
    "def front_page_check(url, keywords):\n",
    "    #selector of main page\n",
    "    url = url\n",
    "    html = requests.get(url).content\n",
    "    sel = Selector(text = html)\n",
    "\n",
    "    #selector of top frontpage contet\n",
    "    front_sel = \"section.frontpage__section\"\n",
    "    front_page = sel.css(front_sel)\n",
    "\n",
    "    #get headline selectors\n",
    "    headlines = front_page.css(\"h2\")\n",
    "\n",
    "    #extract headlines based on keyword\n",
    "    headlines_ext = list()\n",
    "\n",
    "    for headline in headlines:\n",
    "        if keyword_check(keywords, headline) == True:\n",
    "            headlines_ext.append(headline)\n",
    "        \n",
    "    #get links from extracted headlines\n",
    "    links_ext = list()\n",
    "    for headline in headlines_ext:\n",
    "        links_ext.append(headline.css(\"a::attr(href)\").get())\n",
    "    links_ext = list(filter(None, links_ext))\n",
    "    \n",
    "    #get article info\n",
    "    articles = list()\n",
    "\n",
    "    for link in links_ext:\n",
    "        if not link in url_list:\n",
    "            art_info = get_article_info(link)\n",
    "            articles.append(art_info)\n",
    "    \n",
    "    return(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 11:31:24.786353\n",
      "14\n",
      "2020-03-26 11:31:30.623717\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#set keywords\n",
    "#keywords = ['udlænding', 'asyl', 'grænse', 'indvandr', 'udland']\n",
    "keywords = ['corona']\n",
    "\n",
    "i = 2\n",
    "\n",
    "url_list = list()\n",
    "\n",
    "with open('../data/urls/politiken_article_urls.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        url_list.append(line.strip())\n",
    "\n",
    "while i > 0:\n",
    "    response = requests.get('https://politiken.dk/')\n",
    "    if response.status_code == 200:\n",
    "        articles = front_page_check(url = 'https://politiken.dk/', keywords = keywords)\n",
    "        \n",
    "        if len(articles) != 0:\n",
    "            with open('..\\\\data\\\\politiken_articles.json', 'a') as file:\n",
    "                json.dump(articles, file)\n",
    "        \n",
    "        for article in articles:\n",
    "            url_list.append(article['article_link'])\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    print(len(articles))\n",
    "    \n",
    "    i = i - 1\n",
    "    time_out = randint(41*60, 62*60)\n",
    "    time.sleep(time_out)\n",
    "\n",
    "url_list = list(set(url_list))\n",
    "    \n",
    "with open('../data/urls/politiken_article_urls.txt', 'a') as f:\n",
    "    for url in url_list:\n",
    "        f.write(url + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in articles:\n",
    "    pp.pprint(article['article_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(url_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "poldata = pd.read_json('..\\\\data\\\\politiken_articles.json')\n",
    "berdata = pd.read_json('..\\\\data\\\\berlingske_articles.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = poldata.append(berdata, sort = False, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>article_accessed</th>\n",
       "      <th>newspaper_name</th>\n",
       "      <th>newspaper_frontpage_url</th>\n",
       "      <th>frontpage_selector</th>\n",
       "      <th>keywords_search</th>\n",
       "      <th>keywords_match</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_link</th>\n",
       "      <th>article_datetime</th>\n",
       "      <th>encounter_datetime</th>\n",
       "      <th>frontpage_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>f2265dfa-e2bf-40ff-848e-fe787a056e19</td>\n",
       "      <td>1</td>\n",
       "      <td>Politiken</td>\n",
       "      <td>https://politiken.dk/</td>\n",
       "      <td>section.frontpage__section</td>\n",
       "      <td>[udlænding, asyl, grænse, indvandr, udland]</td>\n",
       "      <td>[udland]</td>\n",
       "      <td>Tidligere britisk ambassadør i Danmark: Danmar...</td>\n",
       "      <td>https://politiken.dk/debat/debatindlaeg/art772...</td>\n",
       "      <td>2020-03-24T19:28:22+01:00</td>\n",
       "      <td>2020-03-25 11:27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>52f883ba-420a-4532-bfa8-f48799336ccc</td>\n",
       "      <td>1</td>\n",
       "      <td>Politiken</td>\n",
       "      <td>https://politiken.dk/</td>\n",
       "      <td>section.frontpage__section</td>\n",
       "      <td>[udlænding, asyl, grænse, indvandr, udland]</td>\n",
       "      <td>[udlænding]</td>\n",
       "      <td>R og EL vil have Tesfaye til at lave 'corona-l...</td>\n",
       "      <td>https://politiken.dk/indland/art7723746/R-og-E...</td>\n",
       "      <td>2020-03-25T11:50:12+01:00</td>\n",
       "      <td>2020-03-25 12:24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>438d3274-4309-47f7-a4ec-e8090d713f85</td>\n",
       "      <td>1</td>\n",
       "      <td>Berlingske</td>\n",
       "      <td>https://www.berlingske.dk/</td>\n",
       "      <td>div.front.theme-berlingske</td>\n",
       "      <td>[udlænding, asyl, grænse, indvandr, udland]</td>\n",
       "      <td>[grænse]</td>\n",
       "      <td>Økonom: Der er intet alternativ til at sætte e...</td>\n",
       "      <td>https://www.berlingske.dk/kronikker/oekonom-de...</td>\n",
       "      <td>2020-03-25T08:00:00+01:00</td>\n",
       "      <td>2020-03-25 11:27</td>\n",
       "      <td>økonom: jeg ved, det er upopulært, men vi må ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   uuid  article_accessed newspaper_name  \\\n",
       "0  f2265dfa-e2bf-40ff-848e-fe787a056e19                 1      Politiken   \n",
       "1  52f883ba-420a-4532-bfa8-f48799336ccc                 1      Politiken   \n",
       "2  438d3274-4309-47f7-a4ec-e8090d713f85                 1     Berlingske   \n",
       "\n",
       "      newspaper_frontpage_url          frontpage_selector  \\\n",
       "0       https://politiken.dk/  section.frontpage__section   \n",
       "1       https://politiken.dk/  section.frontpage__section   \n",
       "2  https://www.berlingske.dk/  div.front.theme-berlingske   \n",
       "\n",
       "                               keywords_search keywords_match  \\\n",
       "0  [udlænding, asyl, grænse, indvandr, udland]       [udland]   \n",
       "1  [udlænding, asyl, grænse, indvandr, udland]    [udlænding]   \n",
       "2  [udlænding, asyl, grænse, indvandr, udland]       [grænse]   \n",
       "\n",
       "                                       article_title  \\\n",
       "0  Tidligere britisk ambassadør i Danmark: Danmar...   \n",
       "1  R og EL vil have Tesfaye til at lave 'corona-l...   \n",
       "2  Økonom: Der er intet alternativ til at sætte e...   \n",
       "\n",
       "                                        article_link  \\\n",
       "0  https://politiken.dk/debat/debatindlaeg/art772...   \n",
       "1  https://politiken.dk/indland/art7723746/R-og-E...   \n",
       "2  https://www.berlingske.dk/kronikker/oekonom-de...   \n",
       "\n",
       "            article_datetime encounter_datetime  \\\n",
       "0  2020-03-24T19:28:22+01:00   2020-03-25 11:27   \n",
       "1  2020-03-25T11:50:12+01:00   2020-03-25 12:24   \n",
       "2  2020-03-25T08:00:00+01:00   2020-03-25 11:27   \n",
       "\n",
       "                                     frontpage_title  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2   økonom: jeg ved, det er upopulært, men vi må ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('..\\\\data\\\\newspaper_articles.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
