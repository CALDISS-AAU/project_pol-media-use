{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper til Ekstra-bladet\n",
    "\n",
    "Scraper til politik-sektionen af eb: https://ekstrabladet.dk/nyheder/politik/\n",
    "\n",
    "Nedenstående kode blev udarbejdet i forbindelse med CALDISS workshop 5. februar 2021.\n",
    "\n",
    "## \"Design\" af scraperen: Hvad skal scrapes?\n",
    "\n",
    "- [x] Overskrifter\n",
    "- [x] Links til artikler\n",
    "- [x] Kildekode til artikel\n",
    "- [x] Publikationsdato (og tid) for artiklen\n",
    "- [x] Eksterne links i artiklen\n",
    "- [x] Antal kommentarer til artiklen\n",
    "\n",
    "### Andre interessante datapunkter\n",
    "\n",
    "- Indsamlingstidspunkt (dato og tid)\n",
    "\n",
    "### Parametre\n",
    "\n",
    "- Undgå mest læste sektion i højre side\n",
    "- Undgå generelle nyheder i toppen af side\n",
    "\n",
    "### \"Nice to have\"\n",
    "\n",
    "- Nøgleordssøgning\n",
    "- Redigeringstidspunkter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pakker brugt i scraperen\n",
    "\n",
    "Der bruges følgende pakker:\n",
    "\n",
    "**Web scraping**\n",
    "- `requests`: Tilgå hjemmesider (https://2.python-requests.org/en/master/)\n",
    "- `BeautifulSoup`: Behandling af HTML-kode (https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- `urljoin` fra `urllib.parse`: Til sammensætning af URL's\n",
    "\n",
    "**Databehandling**\n",
    "- `pandas`: Konvertering til tabeldata (https://pandas.pydata.org/)\n",
    "- `numpy`: Talbehandling og missing\n",
    "- `re`: Brug af regular expression til at søge og erstatte tekstmønstre\n",
    "\n",
    "**Tid**\n",
    "- `datetime` fra `datetime`: Arbejde med datoer\n",
    "- `time`: Forsinkelser i script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs # Funktionen importeres med forkortelsen bs\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indlæsning af hjemmeside\n",
    "\n",
    "Vi starter med indlæsning af hjemmesiden: 'https://ekstrabladet.dk/nyheder/politik/'\n",
    "\n",
    "Hjemmesiden tilgås ved at sende en GET request (`requests.get()`). Typen af objekt, der returneres, er et `response` objekt, som vi her kalder `response`.\n",
    "\n",
    "Et `response` objekt indeholder sidens kildekode i attribut `.content`. Dette lagres som separat objekt (`eb_html`).\n",
    "\n",
    "Til sidst konverteres HTML-koden til et `soup` objekt (`ebsoup`) med funktionen `bs` (`BeautifulSoup`-funktionen importeret med forkortelse). Dette gør HTML naviger- og søgbar. Argumentet `\"html.parser\"` fortæller, at koden, som skal behandles, er HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://ekstrabladet.dk/nyheder/politik/')\n",
    "\n",
    "eb_html = response.content\n",
    "\n",
    "ebsoup = bs(eb_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man kan evt. printe HTML-strukturen med nedenstående kommando (dog et voldsomt print).\n",
    "\n",
    "Funktionen er her \"kommenteret ud\" med brug af `#`. `#` fortæller Python, at koden er kommentar, som skal ignoreres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ebsoup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape af links og overskrifter\n",
    "\n",
    "Scraping af links og overskrifter opnås ved at finde et tag eller en sti af tags, der unikt identificerer de dele af siden, som indeholder links og overskrifter.\n",
    "\n",
    "Ved at bruge \"inspector tool\" i en browsers udviklerværktøjer (tilgås typisk med `F12` eller `CTRL + SHIFT + i`), kan vi identificere specifikke HTML tags på siden.\n",
    "\n",
    "Gennem brug af \"inspector tool\" erfares, at både links og overskrifter findes under \"a\" tags (\"a\" tags bruges altid til links). Derudover erfares, at overskrifterne befinder sig i et \"div\" tag med klassen \"flex flex-wrap--wrap flex-justify--between\".\n",
    "\n",
    "Ved først at selektere den specifikke sektion sikrer vi, at vi ikke henter andre links og overskrifter end dem, som er relevante.\n",
    "\n",
    "Vi bruger metoden `.find()` til at isolere det specifikke tag. Det, som returneres, er et nyt `soup` objekt (`section_soup`), som vi også kan søge i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_soup = ebsoup.find('div', class_ = 'flex flex-wrap--wrap flex-justify--between') # Sektion uden mest læste og top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Når sektionen er isoleret, kan vi søge i dette `soup` objekt efter links og overskrifter (\"a\" tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_soups = section_soup.find_all('a') # Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"a\" tags indeholder både overskriften og link til artiklen.\n",
    "\n",
    "Overskriften befinder sig i et \"h2\" tag. For at trække overskriften ud, er vi derfor nødt til at isolere \"h2\"-tagget i hver \"a\" tag (`headline_soups`). Derefter hentes selve teksten for hvert tag (`headlines`).\n",
    "\n",
    "Et \"for loop\" bruges her til at gå igennem hvert \"a\" tag (`link_soups`) og trække \"h2\"-taggenen ud. Derefter bruges et \"for loop\" igen til at tage teksten ud af hvert \"h2\" tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Erhvervsminister Kollerup er tilbage fra sygeorlov',\n",
       " 'Coronahelte får skattesmæk: Nu mødes de om løsning',\n",
       " \"USA's tidligere udenrigsminister George Shultz er død\",\n",
       " 'Nye Borgerlige-profil anklaget for hykleri',\n",
       " 'Engell: Bramsens fjender lugter blod',\n",
       " 'Marzouk fastholder anklager mod Khader',\n",
       " 'Fortidens spøgelser hjemsøger Clinton-familien',\n",
       " 'Franciska Rosenkilde er Alternativets nye leder',\n",
       " 'Anmeldt for overgreb: Politiet stopper efterforskning af Khader',\n",
       " 'Usmagelig madmanøvre fra Mette Makrel',\n",
       " 'Databrud: Styrelse lækker 150.000 cpr-numre',\n",
       " 'Trump presset ud af fagforening',\n",
       " 'USA vil fjerne Yemens Houthi-bevægelse fra terrorliste igen',\n",
       " 'EL vil bruge milliard på trivsel: Flere lærere og lejrskoler',\n",
       " '1000 deltager i største protest mod militærkup i Myanmar',\n",
       " 'Mette F. frygter vaccine-konflikt',\n",
       " 'Ekspert om aggressiv retorik mellem USA og Rusland: En overreaktion',\n",
       " 'Elever skal til færre eksaminer i skoler og gymnasier',\n",
       " 'Ekstra Bladet går mod-live på Mette F.',\n",
       " 'Nyt testkrav fra midnat: Men bornholmerne kan ikke blive lyntestet']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Headlines - omstændig\n",
    "\n",
    "headline_soups = []\n",
    "\n",
    "for link_soup in link_soups:\n",
    "    headline_soups.append(link_soup.find('h2'))\n",
    "\n",
    "headlines = []\n",
    "\n",
    "for headline_soup in headline_soups:\n",
    "    headlines.append(headline_soup.get_text(strip = True))\n",
    "    \n",
    "headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Til links gøres igen brug af et \"for loop\". Links ligger under attribut `href` i \"a\" tagget. Attributter i tags kan tilgås med `[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/nyheder/politik/erhvervsminister-kollerup-er-tilbage-fra-sygeorlov/8465480',\n",
       " '/nyheder/politik/danskpolitik/coronahelte-faar-skattesmaek-nu-moedes-de-om-loesning/8464345',\n",
       " '/nyheder/politik/usas-tidligere-udenrigsminister-george-shultz-er-doed/8465016',\n",
       " '/nyheder/politik/danskpolitik/nye-borgerlige-profil-anklaget-for-hykleri/8464639',\n",
       " '/nyheder/politik/engell-bramsens-fjender-lugter-blod/8464625',\n",
       " '/nyheder/politik/danskpolitik/marzouk-fastholder-anklager-mod-khader/8464850',\n",
       " '/nyheder/politik/fortidens-spoegelser-hjemsoeger-clinton-familien/8444065',\n",
       " '/nyheder/politik/danskpolitik/franciska-rosenkilde-er-alternativets-nye-leder/8464660',\n",
       " '/nyheder/politik/danskpolitik/anmeldt-for-overgreb-politiet-stopper-efterforskning-af-khader/8464779',\n",
       " '/nyheder/politik/danskpolitik/usmagelig-madmanoevre-fra-mette-makrel/8464307',\n",
       " '/nyheder/politik/danskpolitik/databrud-styrelse-laekker-150.000-cpr-numre/8464199',\n",
       " '/nyheder/politik/trump-presset-ud-af-fagforening/8463057',\n",
       " '/nyheder/politik/usa-vil-fjerne-yemens-houthi-bevaegelse-fra-terrorliste-igen/8464040',\n",
       " '/nyheder/politik/danskpolitik/el-vil-bruge-milliard-paa-trivsel-flere-laerere-og-lejrskoler/8464055',\n",
       " '/nyheder/politik/1000-deltager-i-stoerste-protest-mod-militaerkup-i-myanmar/8464049',\n",
       " '/nyheder/politik/mette-f.-frygter-vaccine-konflikt/8463991',\n",
       " '/nyheder/politik/ekspert-om-aggressiv-retorik-mellem-usa-og-rusland-en-overreaktion/8463725',\n",
       " '/nyheder/politik/danskpolitik/elever-skal-til-faerre-eksaminer-i-skoler-og-gymnasier/8463746',\n",
       " '/nyheder/politik/danskpolitik/ekstra-bladet-gaar-mod-live-paa-mette-f./8463577',\n",
       " '/nyheder/politik/nyt-testkrav-fra-midnat-men-bornholmerne-kan-ikke-blive-lyntestet/8463493']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = []\n",
    "\n",
    "for link_soup in link_soups:\n",
    "    links.append(link_soup['href'])\n",
    "    \n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovenstående koder kan kondenseres på flere måder.\n",
    "\n",
    "For det første tillader for loops, at der er flere argumenter. Vi kan derfor køre et for loop, hvor vi både tilføjer til links-listen og headlines-listen.\n",
    "\n",
    "Derudover understøtter Python at man kæder kommandoer sammen. Når man bruger metoder (`.find()` og `.get_text()` er fx metoder), tjekker Python om metoden er kompatibel med typen af objekt, som det bruges på. Derudover returnerer en metode typisk en eller anden form for objekt. Man kan derfor anvende en metode direkte i direkte forlængelse af en anden metode, da Python ved, at den anden metode så skal anvendes på outputtet af den første:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/nyheder/politik/erhvervsminister-kollerup-er-tilbage-fra-sygeorlov/8465480', '/nyheder/politik/danskpolitik/coronahelte-faar-skattesmaek-nu-moedes-de-om-loesning/8464345', '/nyheder/politik/usas-tidligere-udenrigsminister-george-shultz-er-doed/8465016', '/nyheder/politik/danskpolitik/nye-borgerlige-profil-anklaget-for-hykleri/8464639', '/nyheder/politik/engell-bramsens-fjender-lugter-blod/8464625', '/nyheder/politik/danskpolitik/marzouk-fastholder-anklager-mod-khader/8464850', '/nyheder/politik/fortidens-spoegelser-hjemsoeger-clinton-familien/8444065', '/nyheder/politik/danskpolitik/franciska-rosenkilde-er-alternativets-nye-leder/8464660', '/nyheder/politik/danskpolitik/anmeldt-for-overgreb-politiet-stopper-efterforskning-af-khader/8464779', '/nyheder/politik/danskpolitik/usmagelig-madmanoevre-fra-mette-makrel/8464307', '/nyheder/politik/danskpolitik/databrud-styrelse-laekker-150.000-cpr-numre/8464199', '/nyheder/politik/trump-presset-ud-af-fagforening/8463057', '/nyheder/politik/usa-vil-fjerne-yemens-houthi-bevaegelse-fra-terrorliste-igen/8464040', '/nyheder/politik/danskpolitik/el-vil-bruge-milliard-paa-trivsel-flere-laerere-og-lejrskoler/8464055', '/nyheder/politik/1000-deltager-i-stoerste-protest-mod-militaerkup-i-myanmar/8464049', '/nyheder/politik/mette-f.-frygter-vaccine-konflikt/8463991', '/nyheder/politik/ekspert-om-aggressiv-retorik-mellem-usa-og-rusland-en-overreaktion/8463725', '/nyheder/politik/danskpolitik/elever-skal-til-faerre-eksaminer-i-skoler-og-gymnasier/8463746', '/nyheder/politik/danskpolitik/ekstra-bladet-gaar-mod-live-paa-mette-f./8463577', '/nyheder/politik/nyt-testkrav-fra-midnat-men-bornholmerne-kan-ikke-blive-lyntestet/8463493']\n",
      "['Erhvervsminister Kollerup er tilbage fra sygeorlov', 'Coronahelte får skattesmæk: Nu mødes de om løsning', \"USA's tidligere udenrigsminister George Shultz er død\", 'Nye Borgerlige-profil anklaget for hykleri', 'Engell: Bramsens fjender lugter blod', 'Marzouk fastholder anklager mod Khader', 'Fortidens spøgelser hjemsøger Clinton-familien', 'Franciska Rosenkilde er Alternativets nye leder', 'Anmeldt for overgreb: Politiet stopper efterforskning af Khader', 'Usmagelig madmanøvre fra Mette Makrel', 'Databrud: Styrelse lækker 150.000 cpr-numre', 'Trump presset ud af fagforening', 'USA vil fjerne Yemens Houthi-bevægelse fra terrorliste igen', 'EL vil bruge milliard på trivsel: Flere lærere og lejrskoler', '1000 deltager i største protest mod militærkup i Myanmar', 'Mette F. frygter vaccine-konflikt', 'Ekspert om aggressiv retorik mellem USA og Rusland: En overreaktion', 'Elever skal til færre eksaminer i skoler og gymnasier', 'Ekstra Bladet går mod-live på Mette F.', 'Nyt testkrav fra midnat: Men bornholmerne kan ikke blive lyntestet']\n"
     ]
    }
   ],
   "source": [
    "# Links og headlines - kondenseret\n",
    "\n",
    "links = []\n",
    "headlines = []\n",
    "\n",
    "for link_soup in link_soups:\n",
    "    links.append(link_soup['href'])\n",
    "    headlines.append(link_soup.find('h2').get_text(strip = True))\n",
    "    \n",
    "print(links)\n",
    "print(headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Med funktionen `len()` kan vi tjekke, om vi har hentet det samme antal links og headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(links),\n",
    "      len(headlines),\n",
    "     sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artikel-scrape\n",
    "\n",
    "Scraperen skal kunne hente følgende indhold for en artikel:\n",
    "\n",
    "- Kildekode\n",
    "- Dato\n",
    "- Antal kommentarer\n",
    "- Eksterne links\n",
    "- Forfatter\n",
    "\n",
    "Vi starter først med at finde de relevante tags for en artikel. Derefter dannes en funktion ud fra dette, som anvendes på alle artikler. Baseret på de fejl, der opstår, når funktionen kører på alle artikler, tilrettes funktionen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kildekode\n",
    "\n",
    "Vi starter med at lave et soup objekt for en af artiklerne. Da soup objektet netop indeholder kildekoden (HTML), har vi dermed styr på første del, som scrape af artiklen skal indeholde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_url = \"https://ekstrabladet.dk/nyheder/politik/danskpolitik/skal-grilles-om-skandale-interview/8463225\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(article_url)\n",
    "\n",
    "html = response.content\n",
    "\n",
    "artsoup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dato\n",
    "\n",
    "Der er to måder at indhente dato og tidspunkt. Dato og tidspunkt indgår både i selve hjemmeside indholdet i toppen af artiklen (\"span\" tag med klassen \"article-timestamp--top\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fredag  d. 5. feb. 2021 - kl. 10:59\n"
     ]
    }
   ],
   "source": [
    "# date - solution 1\n",
    "artdate = artsoup.find('span', class_ = \"article-timestamp--top\").get_text(strip = True)\n",
    "print(artdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derudover findes dato og tidspunkt også som en del af metadata i HTML'en (conten-attribut i tag \"meta\" med property-attribute \"og:article:published_time\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-05T09:59:33Z\n"
     ]
    }
   ],
   "source": [
    "# date - solution 2\n",
    "artdate2 = artsoup.find('meta', attrs = {'property': 'og:article:published_time'})['content']\n",
    "print(artdate2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der virker til at være en uoverenstemmelse mellem de to tidspunkter. Derfor lagres begge, så man senere kan undersøge, hvilken der giver bedst mening at bruge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antal kommentarer\n",
    "\n",
    "Antal kommentarerer findes under \"span\" tag med id \"fnTalkCommentText\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313 kommentarer\n"
     ]
    }
   ],
   "source": [
    "# n comments\n",
    "ncomments = artsoup.find('span', id = 'fnTalkCommentText').get_text()\n",
    "print(ncomments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da vi blot er interesseret i antal kommentarer, kan vi konverterer det til et heltal (integer).\n",
    "\n",
    "Dette gøres ved først at fjerne teksten \" kommentarer\" og konverterer objektet til et heltal.\n",
    "\n",
    "Teksten fjernes gennem brug af regular expression (`re`). Regular expressions tillader, at man søger efter mønstre i tekst, som man derefter kan erstatte. I regular expression betyder \"\\s\" fx \"whitespace\" (fx et mellemrum), \".\" betyder \"enhver karakter\" og \"*\" betyder \"gentag 0 eller flere gange\". Et regular expression `\"\\s.*\"` matcher derfor tekststykker bestående af et mellemrum efterfulgt af 0 eller flere karakterer.\n",
    "\n",
    "Tekststykker der matcher et regular expression kan erstattes med `re.sub()`. I funktionen skrives først mønstret, som skal erstattes (`'\\s.*'`, dernæst det, som det skal erstattes med (`''` for ingenting) og til sidst teksten, hvor der skal erstattes (`ncomments`):\n",
    "\n",
    "Tallet, som står tilbage i teksten, konverteres til heltal med `int()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\n"
     ]
    }
   ],
   "source": [
    "ncomments_int = int(re.sub(r'\\s.*', '', ncomments))\n",
    "print(ncomments_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksterne links\n",
    "\n",
    "Links er som bekendt altid lagret i \"a\" tags\". For at finde links til andre sider i artikelteksten, skal vi derfor have indskrænket til selve artikelteksten, før der søges efter links.\n",
    "\n",
    "Selve artikelteksten findes i et \"div\" tag med klassen \"article-bodytext\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://olfi.dk/2021/01/27/saadan-koerte-rutineret-journalists-interview-med-forsvarsministeren-helt-af-sporet/', 'https://nyheder.tv2.dk/politik/2021-02-04-forsvarsministeren-beskylder-journalist-for-at-opdigte-skandaleinterview']\n"
     ]
    }
   ],
   "source": [
    "# external links\n",
    "\n",
    "body_soup = artsoup.find('div', class_ = 'article-bodytext')\n",
    "\n",
    "extlink_soups = body_soup.find_all('a')\n",
    "\n",
    "extlinks = []\n",
    "for extlink_soup in extlink_soups:\n",
    "    extlinks.append(extlink_soup['href'])\n",
    "\n",
    "print(extlinks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovenstående kode kan forkortes gennem brug af såkaldt \"list comprehension\" (https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions).\n",
    "\n",
    "\"List comprehension\" gør, at man kombinere et for loop og en liste sådan, at man én gang laver en liste, som består af outputs fra et for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://olfi.dk/2021/01/27/saadan-koerte-rutineret-journalists-interview-med-forsvarsministeren-helt-af-sporet/', 'https://nyheder.tv2.dk/politik/2021-02-04-forsvarsministeren-beskylder-journalist-for-at-opdigte-skandaleinterview']\n"
     ]
    }
   ],
   "source": [
    "# external links - short version\n",
    "extlinks = [extlink_soup['href'] for extlink_soup in artsoup.find('div', class_ = 'article-bodytext').find_all('a')]\n",
    "\n",
    "print(extlinks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forfatter\n",
    "\n",
    "Forfatteren findes umiddelbart i et \"span\" tag med itemprop-attribut med væriden \"author\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James Kristoffer Miles\n"
     ]
    }
   ],
   "source": [
    "# author\n",
    "author = artsoup.find('span', attrs = {'itemprop': 'author'}).get_text(strip = True)\n",
    "print(author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artikelscraper som funktion\n",
    "\n",
    "Nu vi ved, hvordan de forskellige dele hentes, kan vi konverterer dette til en funktion.\n",
    "\n",
    "Vi skriver funktionen sådan, at den tager et link som input/argument (link til artikel). Funktionen tilgår derefter artiklen og henter de relevante informationerne.\n",
    "\n",
    "Informationerne returneres som en såkaldt \"dictionary\" (`article_dict`). En dictionary består af nøgle-værdi par, hvor hver værdi tildeles en vis nøgle. Nøgler i dictionaries kan anvendes lig variable i et datasæt.\n",
    "\n",
    "**Fejlhåndtering**\n",
    "\n",
    "Koden skrevet indtil videre antager, at informationerne altid er der (fx forfatter, antal kommentarer, eksterne links). Det er dog meget sandsynligt, at nogen artikler ikke indeholder alle disse informationer. Funktionen skal derfor kunne tage højde for dette.\n",
    "\n",
    "I funktionen tages højde for dette gennem brug brug af simpel fejlhåndtering med brug af `try` og `except`. `try-except` tillader, at man tager højde for visse fejl i funktionen, sådan at funktionen ikke stopper, hvis den rammer den fejl.\n",
    "\n",
    "Man skriver først en `try`-blok. I den specificerer man den kode, som Python skal forsøge at køre. Man skriver derefter en `except`-blok. `except`-linjen skal gerne indeholde den fejltype, som man forventer at `try`-blokken vil støde på (i dette tilfælde en `AttributeError`). Koden i `except`-blokken køres så i det tilfælde, at den specificerede fejltype sker, når `try`-blokken køres.\n",
    "\n",
    "Sagt kort: Forsøg at kør `try`-koden. Hvis der opstår en `AttributeError`, kør da `except`-koden.\n",
    "\n",
    "Koden kunne sagtens forbedres til at tage højde for flere ting, men her nøjes vi med at forsøge en ting og ellers give en tom værdi, hvis ikke det lykkes. \n",
    "\n",
    "**Obs: Tilgå URL**\n",
    "\n",
    "Der kan opstå mange fejl, når man tilgår links/URL's i Python. Fx kan der nemt opstå en mindre forbindelsesfejl som gør, at man ikke får forbindelse i lige det øjeblik, som man kører koden. \n",
    "\n",
    "Derfor vil man typisk skrive funktioner, som skal få adgang til links, sådan, at de fx forsøger igen eller forsøger noget andet, hvis de støder på nogen bestemte fejltyper.\n",
    "\n",
    "Vær opmærksom på , at vi i denne funktion *ikke* har taget højde for dette!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eb_article_scrape(url):\n",
    "    article_dict = {}\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    html = response.content\n",
    "    artsoup = bs(html, \"html.parser\")\n",
    "    \n",
    "    artdate = artsoup.find('span', class_ = \"article-timestamp--top\").get_text(strip = True)\n",
    "    artdate2 = artsoup.find('meta', attrs = {'property': 'og:article:published_time'})['content']\n",
    "    \n",
    "    try:\n",
    "        ncomments = artsoup.find('span', id = 'fnTalkCommentText').get_text()\n",
    "        ncomments_int = int(re.sub(r'\\s.*', '', ncomments))\n",
    "    except AttributeError: \n",
    "        ncomments_int = np.nan\n",
    "    \n",
    "    try:\n",
    "        extlinks = [extlink_soup['href'] for extlink_soup in artsoup.find('div', class_ = 'article-bodytext').find_all('a')]\n",
    "    except AttributeError:\n",
    "        extlinks = \"\"\n",
    "    \n",
    "    try:\n",
    "        author = artsoup.find('span', attrs = {'itemprop': 'author'}).get_text(strip = True)\n",
    "    except AttributeError:\n",
    "        author = \"\"\n",
    "    \n",
    "    article_dict['source_code'] = str(artsoup)\n",
    "    article_dict['artdate_printed'] = artdate\n",
    "    article_dict['artdate_meta'] = artdate2\n",
    "    article_dict['ncomments'] = ncomments_int\n",
    "    article_dict['extlinks'] = extlinks\n",
    "    article_dict['author'] = author\n",
    "    article_dict['article_url'] = url\n",
    "    \n",
    "    return(article_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Når man laver en funktion med `def` defineres funktionen blot. Den er derfor ikke kørt, men er oprettet, så vi kan anvende den.\n",
    "\n",
    "I nedenstående bruges funktionen på samme artikel som før. Output (dictionary med informationerne) lagres i objektet `article`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = eb_article_scrape(article_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da objektet indeholder kildekoden, vil det fylde en del at printe hele dicionary. Vi kan dog tjekke, hvilke \"nøgler\" dicionary indeholder med `.keys()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['source_code', 'artdate_printed', 'artdate_meta', 'ncomments', 'extlinks', 'author', 'article_url'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan tilgå en af værdierne ved at specificere nøglen i kantede parenteser (`[]`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article['ncomments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anvendelse af funktionen på flere links\n",
    "\n",
    "Når funktionen nu er dannet, kan denne bruges på de indsamlede links.\n",
    "\n",
    "Da de fleste links er hentet som relative links (dvs. links, som tager udgangspunkt i hoveddomænet/hovedsiden), så er vi nødt til at tilføje hoveddomænet hovedsiden til hvert enkelt link.\n",
    "\n",
    "Dette gøres med et for loop. Samtidig bruges funktionen `urljoin()` fra `urllin.parse`, da denne tager højde for, at hoveddomæne/hovedside ikke er en del af linket i forvejen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://ekstrabladet.dk/nyheder/politik/erhvervsminister-kollerup-er-tilbage-fra-sygeorlov/8465480',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/danskpolitik/coronahelte-faar-skattesmaek-nu-moedes-de-om-loesning/8464345',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/usas-tidligere-udenrigsminister-george-shultz-er-doed/8465016',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/danskpolitik/nye-borgerlige-profil-anklaget-for-hykleri/8464639',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/engell-bramsens-fjender-lugter-blod/8464625',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/danskpolitik/marzouk-fastholder-anklager-mod-khader/8464850',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/fortidens-spoegelser-hjemsoeger-clinton-familien/8444065',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/danskpolitik/franciska-rosenkilde-er-alternativets-nye-leder/8464660',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/danskpolitik/anmeldt-for-overgreb-politiet-stopper-efterforskning-af-khader/8464779',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/danskpolitik/usmagelig-madmanoevre-fra-mette-makrel/8464307',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/danskpolitik/databrud-styrelse-laekker-150.000-cpr-numre/8464199',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/trump-presset-ud-af-fagforening/8463057',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/usa-vil-fjerne-yemens-houthi-bevaegelse-fra-terrorliste-igen/8464040',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/danskpolitik/el-vil-bruge-milliard-paa-trivsel-flere-laerere-og-lejrskoler/8464055',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/1000-deltager-i-stoerste-protest-mod-militaerkup-i-myanmar/8464049',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/mette-f.-frygter-vaccine-konflikt/8463991',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/ekspert-om-aggressiv-retorik-mellem-usa-og-rusland-en-overreaktion/8463725',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/danskpolitik/elever-skal-til-faerre-eksaminer-i-skoler-og-gymnasier/8463746',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/danskpolitik/ekstra-bladet-gaar-mod-live-paa-mette-f./8463577',\n",
       " 'https://ekstrabladet.dk/nyheder/politik/nyt-testkrav-fra-midnat-men-bornholmerne-kan-ikke-blive-lyntestet/8463493']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_links = [urljoin(\"https://ekstrabladet.dk\", link) for link in links]\n",
    "new_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape af alle artikler\n",
    "\n",
    "Vi har nu både listen af links og vores scrape-funktion, og vi er nu klar til at scrape alle artiklerne.\n",
    "\n",
    "De enkelte links scrapes med brug af for loop. Artiklerne lagres som en liste (`articles`). Den færdige datastruktur er altså en liste bestående af dictionaries. Hver dictionary indeholder de forskellige informationer fra artiklen.\n",
    "\n",
    "***OBS:*** Med brug af for loops og scrape skal man være varsom. Hvis ikke man indbygger forsinkelser eller andet, så sender man rigtig mange henvendelser til en hjemmeside på næsten ingen tid - det kan dem, som ejer hjemmesiden ikke lide!\n",
    "\n",
    "Nedenståedne kode har indbyggede forsinkelser med `time.sleep()`. Denne funktion sætter koden på pause i det antal sekunder, som man sætter ind. I dette tilfælde venter Python altså 2 sekunder mellem hvert scrape.\n",
    "\n",
    "(jeg har desuden sat et mellemrum i `for`-linjen, så man ikke bare kører denne linje uden at læse efter først)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00%\r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "articles = []\n",
    "\n",
    "for c, link in enumerate(new_links, start = 1):\n",
    "    articles.append(eb_article_scrape(link))\n",
    "    \n",
    "    print(\"{:.2f}%\".format(100.0 * c/len(new_links)), end = '\\r')\n",
    "    \n",
    "    time.sleep(2) #VIGTIGT! Denne kommando gør, at der ventes to sekunder mellem hvert scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tilføj overskrift og link til data\n",
    "\n",
    "Funktionen tilføjer lige nu ikke overskrift og link. Man kunne skrive funktionen om, så den gjorde dette.\n",
    "\n",
    "I dette tilfælde tilføjer vi overskrift og link til listen `articles` ved at gå igennem hver dictionary i listen med et for loop, og tilføje den tilhørende overskrift og link. Dette gøres ved at loope igennem indeks i både artikel-listen (`articles`), overskrift-listen (`headlines`) og link-listen (`new_links`).\n",
    "\n",
    "Da de har samme rækkefølge, kan man loope igennem dem på denne måde (første artikel i artikellisten (`articles[0]`) hører til første headline og link (hhv. `headlines[0]` og `new_links[0]`) osv.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(articles)-1):\n",
    "    articles[i]['headline'] = headlines[i]\n",
    "    articles[i]['url'] = new_links[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konvertering til tabel (data frame)\n",
    "\n",
    "Dataen, som er indsamlet, kan konverteres til en tabelstruktur. Dette gøres gennem pakken `pandas`, hvor man kan arbejde med datastrukturen \"data frame\".\n",
    "\n",
    "Funktionen `pd.DataFrame.from_records()` danner en data frame fra en datastruktur som den, vi har indsamlet artiklerne som (en liste af dictionaries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_code</th>\n",
       "      <th>artdate_printed</th>\n",
       "      <th>artdate_meta</th>\n",
       "      <th>ncomments</th>\n",
       "      <th>extlinks</th>\n",
       "      <th>author</th>\n",
       "      <th>article_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"da\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n",
       "      <td>Mandag  d. 8. feb. 2021 - kl. 08:11</td>\n",
       "      <td>2021-02-08T07:11:29Z</td>\n",
       "      <td>139.0</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>https://ekstrabladet.dk/nyheder/politik/erhver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"da\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n",
       "      <td>Mandag  d. 8. feb. 2021 - kl. 06:55</td>\n",
       "      <td>2021-02-08T05:55:58Z</td>\n",
       "      <td>145.0</td>\n",
       "      <td>[https://ekstrabladet.dk/nyheder/politik/dansk...</td>\n",
       "      <td>Kristian B. Larsen</td>\n",
       "      <td>https://ekstrabladet.dk/nyheder/politik/danskp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"da\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n",
       "      <td>Søndag  d. 7. feb. 2021 - kl. 19:18</td>\n",
       "      <td>2021-02-07T18:18:33Z</td>\n",
       "      <td>16.0</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>https://ekstrabladet.dk/nyheder/politik/usas-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"da\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n",
       "      <td>Søndag  d. 7. feb. 2021 - kl. 19:12</td>\n",
       "      <td>2021-02-07T18:12:31Z</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>[https://ekstrabladet.dk/nyheder/politik/afsae...</td>\n",
       "      <td>Emmely Smith</td>\n",
       "      <td>https://ekstrabladet.dk/nyheder/politik/danskp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"da\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n",
       "      <td>Søndag  d. 7. feb. 2021 - kl. 18:26</td>\n",
       "      <td>2021-02-07T17:26:19Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hans Engell</td>\n",
       "      <td>https://ekstrabladet.dk/nyheder/politik/engell...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source_code  \\\n",
       "0  <!DOCTYPE html>\\n\\n<html lang=\"da\">\\n<head>\\n<...   \n",
       "1  <!DOCTYPE html>\\n\\n<html lang=\"da\">\\n<head>\\n<...   \n",
       "2  <!DOCTYPE html>\\n\\n<html lang=\"da\">\\n<head>\\n<...   \n",
       "3  <!DOCTYPE html>\\n\\n<html lang=\"da\">\\n<head>\\n<...   \n",
       "4  <!DOCTYPE html>\\n\\n<html lang=\"da\">\\n<head>\\n<...   \n",
       "\n",
       "                       artdate_printed          artdate_meta  ncomments  \\\n",
       "0  Mandag  d. 8. feb. 2021 - kl. 08:11  2021-02-08T07:11:29Z      139.0   \n",
       "1  Mandag  d. 8. feb. 2021 - kl. 06:55  2021-02-08T05:55:58Z      145.0   \n",
       "2  Søndag  d. 7. feb. 2021 - kl. 19:18  2021-02-07T18:18:33Z       16.0   \n",
       "3  Søndag  d. 7. feb. 2021 - kl. 19:12  2021-02-07T18:12:31Z     1463.0   \n",
       "4  Søndag  d. 7. feb. 2021 - kl. 18:26  2021-02-07T17:26:19Z        NaN   \n",
       "\n",
       "                                            extlinks              author  \\\n",
       "0                                                 []                       \n",
       "1  [https://ekstrabladet.dk/nyheder/politik/dansk...  Kristian B. Larsen   \n",
       "2                                                 []                       \n",
       "3  [https://ekstrabladet.dk/nyheder/politik/afsae...        Emmely Smith   \n",
       "4                                                 []         Hans Engell   \n",
       "\n",
       "                                         article_url  \n",
       "0  https://ekstrabladet.dk/nyheder/politik/erhver...  \n",
       "1  https://ekstrabladet.dk/nyheder/politik/danskp...  \n",
       "2  https://ekstrabladet.dk/nyheder/politik/usas-t...  \n",
       "3  https://ekstrabladet.dk/nyheder/politik/danskp...  \n",
       "4  https://ekstrabladet.dk/nyheder/politik/engell...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame.from_records(articles)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sæt det hele sammen\n",
    "\n",
    "Nedenstående kondenserer koden til det mest essentielle.\n",
    "\n",
    "Som det forhåbentlig kan ses, er der i sidste ende ikke tale om forfærdelig meget kode, for at være godt på vej til en scraper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://ekstrabladet.dk/nyheder/politik/')\n",
    "\n",
    "eb_html = response.content\n",
    "\n",
    "ebsoup = bs(eb_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_soup = ebsoup.find('div', class_ = 'flex flex-wrap--wrap flex-justify--between') # Sektion uden mest læste og top\n",
    "link_soups = section_soup.find_all('a') # Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Links og headlines - kondenseret\n",
    "\n",
    "links = []\n",
    "headlines = []\n",
    "\n",
    "for link_soup in link_soups:\n",
    "    links.append(link_soup['href'])\n",
    "    headlines.append(link_soup.find('h2').get_text(strip = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eb_article_scrape(url):\n",
    "    article_dict = {}\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    html = response.content\n",
    "    artsoup = bs(html, \"html.parser\")\n",
    "    \n",
    "    artdate = artsoup.find('span', class_ = \"article-timestamp--top\").get_text(strip = True)\n",
    "    artdate2 = artsoup.find('meta', attrs = {'property': 'og:article:published_time'})['content']\n",
    "    \n",
    "    try:\n",
    "        ncomments = artsoup.find('span', id = 'fnTalkCommentText').get_text()\n",
    "        ncomments_int = int(re.sub(r'\\s.*', '', ncomments))\n",
    "    except AttributeError: \n",
    "        ncomments_int = np.nan\n",
    "    \n",
    "    try:\n",
    "        extlinks = [extlink_soup['href'] for extlink_soup in artsoup.find('div', class_ = 'article-bodytext').find_all('a')]\n",
    "    except AttributeError:\n",
    "        extlinks = \"\"\n",
    "    \n",
    "    try:\n",
    "        author = artsoup.find('span', attrs = {'itemprop': 'author'}).get_text(strip = True)\n",
    "    except AttributeError:\n",
    "        author = \"\"\n",
    "    \n",
    "    article_dict['source_code'] = str(artsoup)\n",
    "    article_dict['artdate_printed'] = artdate\n",
    "    article_dict['artdate_meta'] = artdate2\n",
    "    article_dict['ncomments'] = ncomments_int\n",
    "    article_dict['extlinks'] = extlinks\n",
    "    article_dict['author'] = author\n",
    "    article_dict['article_url'] = url\n",
    "    \n",
    "    return(article_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_links = [urljoin(\"https://ekstrabladet.dk\", link) for link in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "\n",
    "f or c, link in enumerate(new_links, start = 1):\n",
    "    articles.append(eb_article_scrape(link))\n",
    "    \n",
    "    print(\"{:.2f}%\".format(100.0 * c/len(new_links)), end = '\\r')\n",
    "    \n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_records(articles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
